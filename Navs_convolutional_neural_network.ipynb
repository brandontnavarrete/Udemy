{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCV30xyVhFbE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIleuCAjoFD8"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0koUcJMJpEBD"
      },
      "source": [
        "\n",
        "# Create an ImageDataGenerator object for training data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,  # Rescale pixel values to range [0,1]\n",
        "                                   shear_range=0.2,  # Apply random shear transformations(shearing is a transformation that tilts or slants the image along a certain axis. It distorts the shape of the image by shifting the pixels in a direction perpendicular to the axis being sheared.)\n",
        "                                   zoom_range=0.2,   # Apply random zoom transformations (Each image in the dataset will undergo a random zoom transformation independently. )\n",
        "                                   horizontal_flip=True)  # Flip images horizontally (random horizantal flips will be applied to images)\n",
        "\n",
        "# Generate batches of augmented training data from the directory\n",
        "training_set = train_datagen.flow_from_directory('/Users/brandonnavarrete/codeup-data-science/Udemy/Part 8 - Deep Learning/Section 40 - Convolutional Neural Networks (CNN)/Python/dataset copy/training_set',\n",
        "                                                 target_size=(64, 64),  # specifies that the images will be resized to a target size of (64, 64) during the augmentation process.\n",
        "                                                 batch_size=32,  # Number of samples per batch\n",
        "                                                 class_mode='binary')  # Class mode is binary ( binary classification tasks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0qED_Js8cKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are a few key reasons why the same transformations are not applied:\n",
        "\n",
        "Preventing data leakage: Data augmentation techniques like shearing, zooming, or flipping introduce modifications to the images that alter their original characteristics. If the same transformations were applied to both the training and test sets, it would result in an overlap of the augmented versions of some images between the two sets. This can lead to data leakage, where the model unknowingly sees augmented versions of the test images during training, compromising the integrity of the evaluation.\n",
        "\n",
        "Evaluating generalization: The primary purpose of the test set is to evaluate how well the trained model generalizes to unseen, real-world data. By using a separate test set, which contains unmodified, unseen images, we obtain a more accurate assessment of the model's performance on real-world data. This evaluation provides insights into how well the model can handle new, unaltered images without relying on the specific transformations used during training.\n",
        "\n",
        "Representative evaluation: The test set is typically treated as a representative sample of the real-world data distribution. If we were to apply the same transformations as the training set, the test set would no longer reflect the distribution of unaltered images that the model will encounter in deployment scenarios. It is crucial to evaluate the model's performance on the original, unaltered images to obtain reliable performance metrics."
      ],
      "metadata": {
        "id": "JbUt1SNG8c1Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH4WzfOhpKc3"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/Users/brandonnavarrete/codeup-data-science/Udemy/Part 8 - Deep Learning/Section 40 - Convolutional Neural Networks (CNN)/Python/dataset copy/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAUt4UMPlhLS"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzPrMckl-hV"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncpqPl69mOac"
      },
      "source": [
        "# Add a MaxPooling layer to the CNN model\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "# add a MaxPooling layer to the Convolutional Neural Network (CNN) model.\n",
        "\n",
        "# pool_size=2: This parameter specifies the size of the pooling window. In this case, it is set to 2, indicating a 2x2 window. The MaxPooling operation downsamples the input feature maps by taking the maximum value within each pooling window.\n",
        "\n",
        "# strides=2: This parameter determines the stride or step size of the pooling window during the pooling operation. Here, it is set to 2, which means the pooling window will move by 2 units horizontally and vertically.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_-FZjn_m8gk"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AZeOGCvnNZn"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GtmUlLd26Nq"
      },
      "source": [
        "# Add a Dense layer to the CNN model\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Add a Dense layer to the CNN model: This comment explains the purpose of the code line, which is to add a Dense layer to the Convolutional Neural Network (CNN) model.\n",
        "\n",
        "# units=128: This parameter specifies the number of neurons or units in the Dense layer. In this case, it is set to 128, indicating that the layer will have 128 neurons.\n",
        "\n",
        "# activation='relu': This parameter sets the activation function for the Dense layer. Here, 'relu' (Rectified Linear Unit) is used as the activation function. The relu activation function introduces non-linearity, allowing the model to learn complex relationships and capture non-linear patterns in the data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p_Zj1Mc3Ko_"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NALksrNQpUlJ"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUj1W4PJptta"
      },
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsSiWEJY1BPB"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED9KB3I54c1i"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}